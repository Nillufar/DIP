import cv2
import mediapipe as mp
import numpy as np

# Initialize Mediapipe Face Detection
mp_face_detection = mp.solutions.face_detection
mp_drawing = mp.solutions.drawing_utils
face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)

# Function to detect lighting conditions
def detect_lighting_conditions(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    avg_brightness = np.mean(gray)
    if avg_brightness < 50:
        return "Shadow Detected"
    elif avg_brightness > 200:
        return "Sunlight Detected"
    else:
        return "Normal Lighting"

# Function to analyze face visibility
def detect_face_cover(face_landmarks, img_width, img_height):
    if face_landmarks:
        for detection in face_landmarks:
            # Get bounding box coordinates
            bbox_c = detection.location_data.relative_bounding_box
            bbox = [
                int(bbox_c.xmin * img_width),
                int(bbox_c.ymin * img_height),
                int(bbox_c.width * img_width),
                int(bbox_c.height * img_height),
            ]
            # Example logic to detect face cover
            if bbox[2] * bbox[3] < 5000:  # If face area is very small
                return "Face Covered"
    return "Face Visible"

# Real-Time Video Stream
cap = cv2.VideoCapture(0)  # Change to a video file path for pre-recorded input

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("Unable to capture video")
        break

    h, w, _ = frame.shape
    lighting_status = detect_lighting_conditions(frame)

    # Convert to RGB for Mediapipe
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = face_detection.process(frame_rgb)

    # Overlay detection results
    if results.detections:
        for detection in results.detections:
            # Draw face detection box
            mp_drawing.draw_detection(frame, detection)
            face_status = detect_face_cover(results.detections, w, h)
            cv2.putText(frame, face_status, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    # Display lighting condition
    cv2.putText(frame, lighting_status, (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    # Show the video feed
    cv2.imshow("Real-Time Detection", frame)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
